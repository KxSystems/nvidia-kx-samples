services:
  aira-instruct-llm:
    container_name: aira-instruct-llm
    image: ${INSTRUCT_LLM_IMAGE:-nvcr.io/nim/meta/llama-3.3-70b-instruct:1.13.1}
    runtime: nvidia
    volumes:
    - ${MODEL_DIRECTORY:-./}:/opt/nim/.cache
    user: "${USERID}"
    ports:
    - "8050:8000"
    expose:
    - "8050"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
      # Automatic profile detection
      NIM_MODEL_PROFILE: ${NIM_MODEL_PROFILE-""}
    shm_size: 20gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              # RAG uses 0,1 so we assign 2,3 to the LLM
              device_ids: ['${AIRA_LLM_MS_GPU_ID:-2,3}']
              capabilities: [gpu] 
    healthcheck:
      test: ["CMD", "python3", "-c", "import requests; requests.get('http://localhost:8000/v1/health/ready')"]
      interval: 30s
      timeout: 20s
      retries: 100
    networks:
      - nvidia-rag
    profiles: ["aira-instruct-llm"]

  aira-backend:
    container_name: aira-backend
    image: ${AIRA_BACKEND_IMAGE:-nvcr.io/nvidia/blueprint/aira-backend:v1.2.0}
    runtime: nvidia
    build:
      context: ../../
      dockerfile: deploy/Dockerfile
    entrypoint: "/entrypoint.sh"
    ports:
      - "3838:3838"
    expose:
      - "3838"
    environment:
      TAVILY_API_KEY: ${TAVILY_API_KEY:-}
      AIRA_APPLY_GUARDRAIL: "false"
      NVIDIA_API_KEY: ${NVIDIA_API_KEY:?NVIDIA_API_KEY is required}
      AIRA_HOSTED_NIMS: ${AIRA_HOSTED_NIMS:-false}
      # Required for rag middleware via fastapi extensions
      RAG_INGEST_URL: ${RAG_INGEST_URL:-http://ingestor-server:8082/v1}
      RAG_SERVER_URL: ${RAG_SERVER_URL:-http://rag-server:8081/v1}
      # KDB+ MCP Server Configuration
      KDB_ENABLED: ${KDB_ENABLED:-false}
      KDB_MCP_ENDPOINT: ${KDB_MCP_ENDPOINT:-http://kdb-mcp-server:8000/mcp}
      KDB_MCP_INTERNAL: ${KDB_MCP_INTERNAL:-false}  # Set to "true" when using blueprint's MCP server
      # LLM endpoints for KDB chat (uses instruct model)
      INSTRUCT_BASE_URL: ${INSTRUCT_BASE_URL:-http://aira-instruct-llm:8000/v1}
      INSTRUCT_MODEL_NAME: ${INSTRUCT_MODEL_NAME:-meta/llama-3.3-70b-instruct}
    volumes:
      - ../../configs:/app/configs
    networks:
      - nvidia-rag
    profiles: ["aira"]
    
  aira-frontend:
    container_name: aira-frontend
    image: ${AIRA_FRONTEND_IMAGE:-nvcr.io/nvidia/blueprint/aira-frontend:v1.2.0}
    ports:
      - "3000:3000"
    expose:
      - "3000"
    networks:
      - nvidia-rag
    environment:
      NVWB_TRIM_PREFIX: true
      INFERENCE_ORIGIN: ${INFERENCE_ORIGIN:-http://aira-backend:3838}
    profiles: ["aira"]

  # KDB-X MCP Server for financial data queries
  # Installs from GitHub at runtime - no pre-built image needed
  # Requires KDB license (kc.lic or k4.lic)
  kdb-mcp-server:
    container_name: kdb-mcp-server
    image: ghcr.io/astral-sh/uv:python3.12-bookworm
    ports:
      - "8100:8000"
    expose:
      - "8000"
    environment:
      # Base64-encoded KDB license (personal or commercial)
      KDB_LICENSE_B64: ${KDB_LICENSE_B64:-}
      KDB_K4LICENSE_B64: ${KDB_K4LICENSE_B64:-}
      # KDB-X server connection (external or kdbx container)
      KDBX_DB_HOST: ${KDBX_DB_HOST:-kdbx-server}
      KDBX_DB_PORT: ${KDBX_DB_PORT:-5000}
      KDBX_MCP_TRANSPORT: "streamable-http"
      KDBX_MCP_HOST: "0.0.0.0"
      KDBX_MCP_PORT: "8000"
      KDBX_MCP_LOG_LEVEL: "INFO"
    volumes:
      # Mount entrypoint script for patches
      - ../helm/kdb-x-mcp-server/entrypoint.sh:/entrypoint.sh:ro
    entrypoint:
      - /bin/bash
      - -c
      - |
        set -e
        echo "=== Installing KDB-X MCP Server at runtime ==="

        # Install git for cloning
        apt-get update && apt-get install -y --no-install-recommends git curl ca-certificates

        # Clone the MCP server repository
        echo "=== Cloning kdb-x-mcp-server from GitHub ==="
        cd /app
        git clone --depth 1 https://github.com/KxSystems/kdb-x-mcp-server.git .
        rm -rf .git

        # Install dependencies
        echo "=== Installing dependencies with uv ==="
        uv sync

        # Upgrade PyKX to latest beta
        echo "=== Upgrading PyKX ==="
        uv pip install --upgrade "pykx>=4.0.0b4"

        # Create license directory
        mkdir -p /opt/kx/lic

        # Activate virtualenv and run the entrypoint script (handles license setup and patches)
        echo "=== Running entrypoint script ==="
        cp /entrypoint.sh /tmp/entrypoint.sh
        chmod +x /tmp/entrypoint.sh
        export PATH="/app/.venv/bin:$PATH"
        exec /tmp/entrypoint.sh
    working_dir: /app
    networks:
      - nvidia-rag
    profiles: ["kdb"]

  # KDB-X database server (optional - can use external KDB-X)
  # Installs KDB-X at runtime - requires KDB_BEARER_TOKEN and KDB_LICENSE_B64
  kdbx-server:
    container_name: kdbx-server
    image: python:3.12-slim-bookworm
    ports:
      - "5000:5000"
    expose:
      - "5000"
    environment:
      KDB_BEARER_TOKEN: ${KDB_BEARER_TOKEN:?KDB_BEARER_TOKEN is required for KDB-X installation}
      KDB_LICENSE_B64: ${KDB_LICENSE_B64:-}
      KDB_K4LICENSE_B64: ${KDB_K4LICENSE_B64:-}
      TERM: xterm
    entrypoint:
      - /bin/bash
      - -c
      - |
        set -e
        echo "=== Installing KDB-X at runtime ==="
        apt-get update && apt-get install -y --no-install-recommends curl ca-certificates libssl-dev unzip

        echo "=== Downloading KDB-X installer ==="
        cd /tmp
        curl -sLO --oauth2-bearer "$${KDB_BEARER_TOKEN}" \
          https://portal.dl.kx.com/assets/raw/kdb-x/install_kdb/~latest~/install_kdb.sh
        chmod +x install_kdb.sh

        echo "=== Installing KDB-X ==="
        export HOME=/opt/kx
        mkdir -p /opt/kx

        if [ -n "$${KDB_K4LICENSE_B64}" ]; then
          echo "Using commercial license (k4)"
          ./install_kdb.sh -y --b64lic "$${KDB_K4LICENSE_B64}" 2>&1
        else
          echo "Using personal license (kc)"
          ./install_kdb.sh -y --b64lic "$${KDB_LICENSE_B64}" 2>&1
        fi
        rm -f install_kdb.sh

        echo "=== Starting KDB-X with SQL interface on port 5000 ==="
        export QHOME="/opt/kx/.kx"
        export QLIC="/opt/kx/.kx"
        # Create startup script to initialize SQL interface
        echo '.s.init[]' > /tmp/startup.q
        echo '-1 "KDB-X ready with SQL interface"' >> /tmp/startup.q
        /opt/kx/.kx/bin/q /tmp/startup.q -p 5000
    networks:
      - nvidia-rag
    profiles: ["kdb"]

# Use the nvidia-rag network created by the
# RAG docker compose deployment
# If you are deploying RAG separately
# set external to false
networks:
  nvidia-rag:
    external: true
    name: nvidia-rag
