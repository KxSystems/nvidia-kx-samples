---
# ConfigMap for SEC Loader configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: sec-loader-config
  labels:
    app: sec-loader
data:
  # Enable/disable the SEC loader
  SEC_LOADER_ENABLED: "true"

  # Symbols to download (comma-separated)
  SEC_LOADER_SYMBOLS: "AAPL,GOOG,MSFT,TSLA,AMZN,NVDA,META,RIVN"

  # Number of years of filings to download
  SEC_LOADER_YEARS: "5"

  # Ingestor server URL (internal Kubernetes service)
  SEC_INGESTOR_URL: "http://ingestor-server:8082"

  # Collection name for storing filings
  SEC_COLLECTION_NAME: "sec_filings"

  # Delay between uploads (seconds)
  SEC_UPLOAD_DELAY: "60"

  # Directory for downloaded files
  SEC_DATA_DIR: "/data/sec_filings"

---
# PersistentVolumeClaim for storing downloaded filings
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: sec-loader-data
  labels:
    app: sec-loader
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  # Uncomment and set storageClassName if needed
  # storageClassName: gp3

---
# Job to download and index SEC filings
apiVersion: batch/v1
kind: Job
metadata:
  name: sec-loader
  labels:
    app: sec-loader
spec:
  # Don't restart on failure, let admin investigate
  backoffLimit: 2
  # Keep job for 24 hours after completion
  ttlSecondsAfterFinished: 86400
  template:
    metadata:
      labels:
        app: sec-loader
    spec:
      restartPolicy: OnFailure
      # Wait for ingestor to be ready
      initContainers:
        - name: wait-for-ingestor
          image: curlimages/curl:8.5.0
          command:
            - /bin/sh
            - -c
            - |
              echo "Waiting for ingestor-server to be ready..."
              until curl -sf http://ingestor-server:8082/health; do
                echo "Ingestor not ready, waiting 10s..."
                sleep 10
              done
              echo "Ingestor is ready!"
      containers:
        - name: sec-loader
          image: python:3.12-slim
          command:
            - /bin/bash
            - -c
            - |
              set -e
              echo "Installing dependencies..."
              pip install --quiet requests

              echo "Running SEC Filings Loader..."
              python /scripts/sec_filings_loader.py --force

          envFrom:
            - configMapRef:
                name: sec-loader-config
          volumeMounts:
            - name: scripts
              mountPath: /scripts
              readOnly: true
            - name: data
              mountPath: /data
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
      volumes:
        - name: scripts
          configMap:
            name: sec-loader-scripts
        - name: data
          persistentVolumeClaim:
            claimName: sec-loader-data

---
# ConfigMap containing the loader script
apiVersion: v1
kind: ConfigMap
metadata:
  name: sec-loader-scripts
  labels:
    app: sec-loader
data:
  sec_filings_loader.py: |
    #!/usr/bin/env python3
    """
    SEC Filings Loader - Kubernetes Version
    Downloads SEC 10-K filings and indexes them into the RAG system.
    """

    import os
    import sys
    import time
    import requests
    from datetime import datetime
    from typing import Optional, List
    from pathlib import Path

    # Configuration from environment
    def get_env_bool(key: str, default: bool = False) -> bool:
        val = os.environ.get(key, str(default)).lower()
        return val in ("true", "1", "yes", "on")

    def get_env_list(key: str, default: List[str]) -> List[str]:
        val = os.environ.get(key, "")
        if val:
            return [s.strip() for s in val.split(",") if s.strip()]
        return default

    def get_env_int(key: str, default: int) -> int:
        try:
            return int(os.environ.get(key, default))
        except ValueError:
            return default

    DEFAULT_SYMBOLS = ["AAPL", "GOOG", "MSFT", "TSLA", "AMZN", "NVDA", "META", "RIVN"]

    CONFIG = {
        "enabled": get_env_bool("SEC_LOADER_ENABLED", False),
        "symbols": get_env_list("SEC_LOADER_SYMBOLS", DEFAULT_SYMBOLS),
        "years": get_env_int("SEC_LOADER_YEARS", 5),
        "ingestor_url": os.environ.get("SEC_INGESTOR_URL", "http://ingestor-server:8082"),
        "collection_name": os.environ.get("SEC_COLLECTION_NAME", "sec_filings"),
        "upload_delay": get_env_int("SEC_UPLOAD_DELAY", 60),
        "data_dir": os.environ.get("SEC_DATA_DIR", "/data/sec_filings"),
    }

    # SEC EDGAR API
    SEC_USER_AGENT = "SEC-Filings-Loader/1.0 (nvidia-rag@example.com)"
    SEC_API_BASE_URL = "https://data.sec.gov"
    SEC_ARCHIVE_BASE_URL = "https://www.sec.gov"
    SEC_REQUEST_DELAY = 0.15

    CIK_MAP = {
        "AAPL": "0000320193", "GOOG": "0001652044", "GOOGL": "0001652044",
        "MSFT": "0000789019", "TSLA": "0001318605", "AMZN": "0000001018",
        "NVDA": "0001045810", "META": "0001326801", "RIVN": "0001874178",
    }

    def get_sec_headers() -> dict:
        return {"User-Agent": SEC_USER_AGENT, "Accept": "application/json"}

    def get_company_cik(ticker: str) -> Optional[str]:
        if ticker.upper() in CIK_MAP:
            return CIK_MAP[ticker.upper()]
        try:
            url = f"{SEC_API_BASE_URL}/submissions/CIK{ticker.upper()}.json"
            response = requests.get(url, headers=get_sec_headers(), timeout=30)
            if response.status_code == 200:
                return response.json().get("cik", "").zfill(10)
        except Exception as e:
            print(f"  Warning: Could not find CIK for {ticker}: {e}")
        return None

    def get_company_filings(cik: str, form_type: str = "10-K", years: int = 5) -> list:
        filings = []
        current_year = datetime.now().year
        min_year = current_year - years
        try:
            url = f"{SEC_API_BASE_URL}/submissions/CIK{cik}.json"
            response = requests.get(url, headers=get_sec_headers(), timeout=30)
            response.raise_for_status()
            data = response.json()
            recent = data.get("filings", {}).get("recent", {})
            forms = recent.get("form", [])
            accession_numbers = recent.get("accessionNumber", [])
            filing_dates = recent.get("filingDate", [])
            primary_docs = recent.get("primaryDocument", [])
            for i, form in enumerate(forms):
                if form == form_type:
                    filing_date = filing_dates[i]
                    filing_year = int(filing_date[:4])
                    if filing_year >= min_year:
                        filings.append({
                            "form": form,
                            "accession_number": accession_numbers[i],
                            "filing_date": filing_date,
                            "primary_document": primary_docs[i],
                            "fiscal_year": filing_year,
                        })
        except Exception as e:
            print(f"  Error fetching filings: {e}")
        return filings

    def download_filing(cik: str, accession_number: str, primary_document: str) -> Optional[str]:
        accession_no_dashes = accession_number.replace("-", "")
        cik_stripped = cik.lstrip("0")
        url = f"{SEC_ARCHIVE_BASE_URL}/Archives/edgar/data/{cik_stripped}/{accession_no_dashes}/{primary_document}"
        try:
            response = requests.get(url, headers=get_sec_headers(), timeout=60)
            if response.status_code == 200:
                return response.text
        except Exception as e:
            print(f"  Error downloading {url}: {e}")
        return None

    def download_filings_for_symbol(ticker: str, output_dir: Path, years: int = 5) -> List[Path]:
        print(f"\n{'='*60}\nDownloading {ticker} filings\n{'='*60}")
        downloaded_files = []
        cik = get_company_cik(ticker)
        if not cik:
            print(f"  Skipping {ticker}: CIK not found")
            return downloaded_files
        print(f"  CIK: {cik}")
        time.sleep(SEC_REQUEST_DELAY)
        filings = get_company_filings(cik, "10-K", years)
        print(f"  Found {len(filings)} 10-K filings in last {years} years")
        if not filings:
            return downloaded_files
        ticker_dir = output_dir / ticker
        ticker_dir.mkdir(parents=True, exist_ok=True)
        for filing in filings:
            fiscal_year = filing["fiscal_year"]
            output_filename = f"{ticker}_10K_{fiscal_year}.html"
            output_path = ticker_dir / output_filename
            if output_path.exists():
                print(f"  Skipping {output_filename} (already exists)")
                downloaded_files.append(output_path)
                continue
            print(f"  Downloading {output_filename}...")
            time.sleep(SEC_REQUEST_DELAY)
            content = download_filing(cik, filing["accession_number"], filing["primary_document"])
            if content:
                with open(output_path, "w", encoding="utf-8") as f:
                    f.write(content)
                print(f"    Saved: {output_path}")
                downloaded_files.append(output_path)
            else:
                print(f"    Failed to download")
            time.sleep(SEC_REQUEST_DELAY)
        return downloaded_files

    def check_ingestor_health(ingestor_url: str, max_retries: int = 30, retry_delay: int = 10) -> bool:
        print(f"Checking ingestor health at {ingestor_url}...")
        for attempt in range(max_retries):
            try:
                response = requests.get(f"{ingestor_url}/health", timeout=10)
                if response.status_code == 200:
                    print("Ingestor is healthy!")
                    return True
            except Exception:
                pass
            if attempt < max_retries - 1:
                print(f"  Attempt {attempt + 1}/{max_retries} failed, retrying in {retry_delay}s...")
                time.sleep(retry_delay)
        print("ERROR: Ingestor is not healthy after all retries")
        return False

    def upload_file_to_ingestor(file_path: Path, ingestor_url: str, collection_name: str) -> dict:
        url = f"{ingestor_url}/documents"
        try:
            with open(file_path, "rb") as f:
                files = {"documents": (file_path.name, f, "text/html")}
                data = {"data": f'{{"collection_name": "{collection_name}", "blocking": false}}'}
                response = requests.post(url, files=files, data=data, timeout=300)
                response.raise_for_status()
                return {"status": "submitted", "response": response.json()}
        except Exception as e:
            return {"status": "error", "error": str(e)}

    def wait_for_task(ingestor_url: str, task_id: str, max_wait: int = 600) -> dict:
        start_time = time.time()
        url = f"{ingestor_url}/task/{task_id}"
        while time.time() - start_time < max_wait:
            try:
                response = requests.get(url, timeout=30)
                if response.status_code == 200:
                    data = response.json()
                    status = data.get("status", "unknown")
                    if status in ("completed", "failed"):
                        return data
                elif response.status_code == 404:
                    return {"status": "completed"}
            except Exception:
                pass
            time.sleep(5)
        return {"status": "timeout"}

    def main():
        if not CONFIG["enabled"]:
            print("SEC Loader is disabled. Set SEC_LOADER_ENABLED=true to enable.")
            sys.exit(0)

        symbols = CONFIG["symbols"]
        years = CONFIG["years"]
        data_dir = Path(CONFIG["data_dir"])
        ingestor_url = CONFIG["ingestor_url"]
        collection_name = CONFIG["collection_name"]
        upload_delay = CONFIG["upload_delay"]

        print("=" * 60)
        print("SEC Filings Loader")
        print("=" * 60)
        print(f"Symbols: {', '.join(symbols)}")
        print(f"Years: {years}")
        print(f"Data Directory: {data_dir}")
        print(f"Ingestor URL: {ingestor_url}")
        print(f"Collection: {collection_name}")

        data_dir.mkdir(parents=True, exist_ok=True)

        # Download phase
        print("\n" + "=" * 60)
        print("PHASE 1: Downloading SEC Filings")
        print("=" * 60)
        all_files = []
        for symbol in symbols:
            files = download_filings_for_symbol(symbol, data_dir, years)
            all_files.extend(files)
        print(f"\nDownloaded {len(all_files)} files total")

        # Upload phase
        if all_files:
            print("\n" + "=" * 60)
            print("PHASE 2: Indexing into RAG System")
            print("=" * 60)
            if not check_ingestor_health(ingestor_url):
                sys.exit(1)
            success = 0
            failed = 0
            for i, file_path in enumerate(all_files, 1):
                print(f"\n[{i}/{len(all_files)}] Uploading {file_path.parent.name}/{file_path.name}...")
                result = upload_file_to_ingestor(file_path, ingestor_url, collection_name)
                if result["status"] == "submitted":
                    task_id = result["response"].get("task_id")
                    print(f"  Submitted: task_id={task_id}")
                    print(f"  Waiting for completion...")
                    task_result = wait_for_task(ingestor_url, task_id)
                    task_status = task_result.get("status", "unknown")
                    print(f"  Task status: {task_status}")
                    if task_status == "completed":
                        success += 1
                    else:
                        failed += 1
                else:
                    print(f"  Error: {result.get('error', 'Unknown error')}")
                    failed += 1
                if i < len(all_files):
                    print(f"  Waiting {upload_delay}s before next upload...")
                    time.sleep(upload_delay)
            print("\n" + "=" * 60)
            print("SEC Filings Loader Complete!")
            print(f"  Successfully indexed: {success}")
            print(f"  Failed: {failed}")
            print("=" * 60)
            sys.exit(0 if failed == 0 else 1)

    if __name__ == "__main__":
        main()
