# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# On-Premises GPU Cluster - Docker Compose
#
# This deploys the GPU-intensive components for hybrid architecture:
#   - KDB.AI with cuVS (GPU-accelerated vector database)
#   - Embedding NIM (GPU)
#   - Reranker NIM (GPU)
#   - NV-Ingest with GPU NIMs
#   - MinIO (object storage)
#
# The cloud cluster connects to these services via VPN/Direct Connect.
#
# Prerequisites:
#   1. NVIDIA GPU drivers and nvidia-container-toolkit installed
#   2. Required environment variables set (see .env.onprem-gpu)
#   3. Network accessible from cloud cluster
#
# Usage:
#   # Copy and configure environment
#   cp .env.onprem-gpu .env.onprem-gpu.local
#   # Edit with your credentials
#   source .env.onprem-gpu.local
#
#   # Start GPU services
#   docker compose -f docker-compose-onprem-gpu.yaml up -d
#
#   # Check GPU utilization
#   nvidia-smi
#
# Network Configuration:
#   Services are exposed on the following ports:
#   - KDB.AI: 8082 (vector database)
#   - Embedding NIM: 8000 (embeddings)
#   - Reranker NIM: 8001 (reranking)
#   - NV-Ingest: 7670 (document processing)
#   - MinIO: 9000 (object storage), 9001 (console)
#
#   Configure your DNS or /etc/hosts on cloud cluster:
#   10.0.0.50  kdbai.onprem.internal
#   10.0.0.50  embedding-nim.onprem.internal
#   10.0.0.50  reranker-nim.onprem.internal
#   10.0.0.50  nv-ingest.onprem.internal
#   10.0.0.50  minio.onprem.internal

services:
  # ===========================================================================
  # KDB.AI Vector Database with cuVS GPU Acceleration
  # ===========================================================================
  kdbai:
    container_name: kdbai
    image: ext-dev-registry.kxi-dev.kx.com/kdbai-db:1.8.1-rc.2-cuvs
    ports:
      - "8081:8081"  # REST API
      - "8082:8082"  # Client API (used by RAG)
    environment:
      KDB_LICENSE_B64: ${KDB_LICENSE_B64}
      KDBAI_THREADS: ${KDBAI_THREADS:-8}
    volumes:
      - kdbai-data:/tmp/kx/data/vdb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${KDBAI_GPU_DEVICE_ID:-0}"]
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/api/v2/ready"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - gpu-network

  # ===========================================================================
  # Embedding NIM (GPU)
  # ===========================================================================
  embedding-nim:
    container_name: embedding-nim
    image: nvcr.io/nim/nvidia/llama-3.2-nv-embedqa-1b-v2:1.9.0
    ports:
      - "8000:8000"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
      NIM_CACHE_PATH: /opt/nim/.cache
    volumes:
      - embedding-cache:/opt/nim/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${EMBEDDING_GPU_DEVICE_ID:-1}"]
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 300s
    restart: unless-stopped
    networks:
      - gpu-network

  # ===========================================================================
  # Reranker NIM (GPU)
  # ===========================================================================
  reranker-nim:
    container_name: reranker-nim
    image: nvcr.io/nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:1.7.0
    ports:
      - "8001:8000"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
      NIM_CACHE_PATH: /opt/nim/.cache
    volumes:
      - reranker-cache:/opt/nim/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${RERANKER_GPU_DEVICE_ID:-1}"]  # Can share with embedding
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 300s
    restart: unless-stopped
    networks:
      - gpu-network

  # ===========================================================================
  # NV-Ingest Document Processing (Multiple GPU NIMs)
  # ===========================================================================
  nv-ingest:
    container_name: nv-ingest
    image: nvcr.io/nvidia/nemo-microservices/nv-ingest:25.9.0
    ports:
      - "7670:7670"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
      # GPU NIM endpoints (running as separate containers or internally)
      NEMORETRIEVER_PARSE_HTTP_URI: "http://page-elements:8000"
      NEMORETRIEVER_GRAPHICS_HTTP_URI: "http://graphic-elements:8000"
      NEMORETRIEVER_TABLE_HTTP_URI: "http://table-structure:8000"
      # MinIO configuration
      MINIO_INTERNAL_ADDRESS: "minio:9000"
      MINIO_PUBLIC_ADDRESS: "http://minio:9000"
      MINIO_BUCKET: "nv-ingest"
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY:-minioadmin}
      # Redis
      MESSAGE_CLIENT_HOST: "redis"
      MESSAGE_CLIENT_PORT: "6379"
    depends_on:
      - redis
      - minio
      - page-elements
      - graphic-elements
      - table-structure
    deploy:
      resources:
        limits:
          memory: 24G
        reservations:
          memory: 12G
    restart: unless-stopped
    networks:
      - gpu-network

  # ===========================================================================
  # NV-Ingest GPU NIMs
  # ===========================================================================
  page-elements:
    container_name: page-elements
    image: nvcr.io/nvidia/nemo-microservices/nemoretriever-page-elements-v2:25.9.0
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${PAGE_ELEMENTS_GPU_ID:-2}"]
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - gpu-network

  graphic-elements:
    container_name: graphic-elements
    image: nvcr.io/nvidia/nemo-microservices/nemoretriever-graphic-elements-v1:25.9.0
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${GRAPHIC_ELEMENTS_GPU_ID:-3}"]
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - gpu-network

  table-structure:
    container_name: table-structure
    image: nvcr.io/nvidia/nemo-microservices/nemoretriever-table-structure-v1:25.9.0
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${TABLE_STRUCTURE_GPU_ID:-4}"]
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - gpu-network

  # ===========================================================================
  # Redis (Required by NV-Ingest)
  # ===========================================================================
  redis:
    container_name: redis
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped
    networks:
      - gpu-network

  # ===========================================================================
  # MinIO Object Storage
  # ===========================================================================
  minio:
    container_name: minio
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # Console
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY:-minioadmin}
    volumes:
      - minio-data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - gpu-network

  # Create default bucket on startup
  minio-init:
    container_name: minio-init
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 ${MINIO_ACCESS_KEY:-minioadmin} ${MINIO_SECRET_KEY:-minioadmin};
      mc mb myminio/nv-ingest --ignore-existing;
      exit 0;
      "
    networks:
      - gpu-network

volumes:
  kdbai-data:
    driver: local
  embedding-cache:
    driver: local
  reranker-cache:
    driver: local
  redis-data:
    driver: local
  minio-data:
    driver: local

networks:
  gpu-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
